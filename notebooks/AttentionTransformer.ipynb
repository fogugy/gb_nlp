{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 50\n",
    "latent_dim = 256\n",
    "num_samples = 10000\n",
    "data_path = 'data/rus-eng/rus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем из текстов токены и делаем pne-hot вектора на каждый токен\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 33s 265ms/step - loss: 1.1533 - accuracy: 0.7671 - val_loss: 0.9015 - val_accuracy: 0.7585\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 29s 236ms/step - loss: 0.7276 - accuracy: 0.8059 - val_loss: 0.7688 - val_accuracy: 0.7961\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 27s 219ms/step - loss: 0.6258 - accuracy: 0.8346 - val_loss: 0.6740 - val_accuracy: 0.8176\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 27s 214ms/step - loss: 0.5563 - accuracy: 0.8465 - val_loss: 0.6205 - val_accuracy: 0.8256\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 28s 225ms/step - loss: 0.5878 - accuracy: 0.8424 - val_loss: 0.6251 - val_accuracy: 0.8221\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 27s 218ms/step - loss: 0.5134 - accuracy: 0.8546 - val_loss: 0.5824 - val_accuracy: 0.8330\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 30s 237ms/step - loss: 0.4901 - accuracy: 0.8600 - val_loss: 0.5628 - val_accuracy: 0.8377\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 27s 216ms/step - loss: 0.4741 - accuracy: 0.8637 - val_loss: 0.5509 - val_accuracy: 0.8415\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 28s 223ms/step - loss: 0.4599 - accuracy: 0.8670 - val_loss: 0.5386 - val_accuracy: 0.8429\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 26s 206ms/step - loss: 0.4465 - accuracy: 0.8705 - val_loss: 0.5276 - val_accuracy: 0.8460\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 28s 226ms/step - loss: 0.4337 - accuracy: 0.8742 - val_loss: 0.5150 - val_accuracy: 0.8497\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 26s 209ms/step - loss: 0.4215 - accuracy: 0.8778 - val_loss: 0.5055 - val_accuracy: 0.8534\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 0.4106 - accuracy: 0.8805 - val_loss: 0.4980 - val_accuracy: 0.8565\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 27s 213ms/step - loss: 0.4004 - accuracy: 0.8832 - val_loss: 0.4905 - val_accuracy: 0.8579\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 28s 221ms/step - loss: 0.3899 - accuracy: 0.8864 - val_loss: 0.4872 - val_accuracy: 0.8581\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 29s 233ms/step - loss: 0.3801 - accuracy: 0.8893 - val_loss: 0.4795 - val_accuracy: 0.8606\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 30s 238ms/step - loss: 0.3710 - accuracy: 0.8917 - val_loss: 0.4756 - val_accuracy: 0.8629\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 30s 239ms/step - loss: 0.3603 - accuracy: 0.8948 - val_loss: 0.4709 - val_accuracy: 0.8640\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 30s 240ms/step - loss: 0.3518 - accuracy: 0.8972 - val_loss: 0.4645 - val_accuracy: 0.8667\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 30s 238ms/step - loss: 0.3425 - accuracy: 0.8999 - val_loss: 0.4614 - val_accuracy: 0.8678\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 34s 273ms/step - loss: 0.3345 - accuracy: 0.9025 - val_loss: 0.4571 - val_accuracy: 0.8682\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 32s 254ms/step - loss: 0.3259 - accuracy: 0.9049 - val_loss: 0.4514 - val_accuracy: 0.8706\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 38s 302ms/step - loss: 0.3169 - accuracy: 0.9073 - val_loss: 0.4498 - val_accuracy: 0.8713\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 35s 282ms/step - loss: 0.3092 - accuracy: 0.9096 - val_loss: 0.4482 - val_accuracy: 0.8720\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 29s 236ms/step - loss: 0.3010 - accuracy: 0.9118 - val_loss: 0.4460 - val_accuracy: 0.8731\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 30s 240ms/step - loss: 0.2927 - accuracy: 0.9144 - val_loss: 0.4431 - val_accuracy: 0.8749\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 32s 258ms/step - loss: 0.2858 - accuracy: 0.9166 - val_loss: 0.4407 - val_accuracy: 0.8759\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 30s 243ms/step - loss: 0.2779 - accuracy: 0.9183 - val_loss: 0.4398 - val_accuracy: 0.8767\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 34s 273ms/step - loss: 0.2699 - accuracy: 0.9210 - val_loss: 0.4399 - val_accuracy: 0.8763\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 0.2632 - accuracy: 0.9228 - val_loss: 0.4405 - val_accuracy: 0.8769\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 32s 252ms/step - loss: 0.2559 - accuracy: 0.9247 - val_loss: 0.4412 - val_accuracy: 0.8763\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 31s 247ms/step - loss: 0.2484 - accuracy: 0.9269 - val_loss: 0.4401 - val_accuracy: 0.8774\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 33s 264ms/step - loss: 0.2414 - accuracy: 0.9287 - val_loss: 0.4440 - val_accuracy: 0.8779\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 31s 251ms/step - loss: 0.2350 - accuracy: 0.9305 - val_loss: 0.4408 - val_accuracy: 0.8789\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.2283 - accuracy: 0.9326 - val_loss: 0.4438 - val_accuracy: 0.8794\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 33s 263ms/step - loss: 0.2221 - accuracy: 0.9339 - val_loss: 0.4451 - val_accuracy: 0.8792\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 28s 221ms/step - loss: 0.2151 - accuracy: 0.9361 - val_loss: 0.4459 - val_accuracy: 0.8797\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 30s 237ms/step - loss: 0.2082 - accuracy: 0.9382 - val_loss: 0.4519 - val_accuracy: 0.8791\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 28s 225ms/step - loss: 0.2021 - accuracy: 0.9400 - val_loss: 0.4530 - val_accuracy: 0.8794\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 28s 223ms/step - loss: 0.1971 - accuracy: 0.9412 - val_loss: 0.4586 - val_accuracy: 0.8790\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 27s 219ms/step - loss: 0.1951 - accuracy: 0.9415 - val_loss: 0.4541 - val_accuracy: 0.8797\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.1850 - accuracy: 0.9447 - val_loss: 0.4588 - val_accuracy: 0.8802\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 35s 279ms/step - loss: 0.1791 - accuracy: 0.9464 - val_loss: 0.4649 - val_accuracy: 0.8804\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 32s 254ms/step - loss: 0.1738 - accuracy: 0.9481 - val_loss: 0.4696 - val_accuracy: 0.8801\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 32s 256ms/step - loss: 0.1684 - accuracy: 0.9497 - val_loss: 0.4717 - val_accuracy: 0.8810\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 27s 218ms/step - loss: 0.1627 - accuracy: 0.9512 - val_loss: 0.4765 - val_accuracy: 0.8795\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 29s 231ms/step - loss: 0.1579 - accuracy: 0.9526 - val_loss: 0.4820 - val_accuracy: 0.8799\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 28s 224ms/step - loss: 0.1538 - accuracy: 0.9538 - val_loss: 0.4845 - val_accuracy: 0.8809\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 28s 225ms/step - loss: 0.1501 - accuracy: 0.9546 - val_loss: 0.4881 - val_accuracy: 0.8799\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.1447 - accuracy: 0.9562 - val_loss: 0.4903 - val_accuracy: 0.8803\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здрасте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здрасте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здрасте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здрасте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здрасте.\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Бегите!\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Бегите!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Бегите!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Бегите!\n",
      "\n",
      "-\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Кто?\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Здорово!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Здорово!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Здорово!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Здорово!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Здорово!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Здорово!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Пожар!\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Пожар!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите!\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Прыгай!\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Прыгай!\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Прыгай!\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Прыгай!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Остановитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Остановитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Остановитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди.\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди.\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди.\n",
      "\n",
      "-\n",
      "Input sentence: Do it.\n",
      "Decoded sentence: Полодей.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Продолжай.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Продолжай.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет!\n",
      "\n",
      "-\n",
      "Input sentence: Hurry!\n",
      "Decoded sentence: Поспешите.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я бежала.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я бежала.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я бежала.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я бежала.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я вижу.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я вижу.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я вижу.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я потросала.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я потросала.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я потросала.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я победил!\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я победил!\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я победил!\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я победил!\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: А нете!\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Расслабьтесь.\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Расслабьтесь.\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Расслабьтесь.\n",
      "\n",
      "-\n",
      "Input sentence: Shoot!\n",
      "Decoded sentence: Стреляй!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбайся.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбайся.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбайся.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбайся.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбайся.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбайся.\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Слайту!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: За ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: За ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: За ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: За ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: За ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Eat it.\n",
      "Decoded sentence: Съешь это.\n",
      "\n",
      "-\n",
      "Input sentence: Eat up.\n",
      "Decoded sentence: Поеду си.\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Застынь!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Застынь!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Застынь!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Застынь!\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Поднимайся.\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Поднимайся.\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Поднимайся.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите сейчас.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Увый!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Усек?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Усек?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Усек?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Усек?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поднимемся на уровень слов, чтобы можно было что-то более адекватное посчитать за адекватное время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "num_samples = 10000\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(preprocess_sentence(input_text))\n",
    "    target_texts.append(preprocess_sentence(target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
    "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.lstm(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "    \n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.1100\n",
      "Epoch 2 Loss 0.0307\n",
      "Epoch 3 Loss 0.0243\n",
      "Epoch 4 Loss 0.0211\n",
      "Epoch 5 Loss 0.0201\n",
      "Epoch 6 Loss 0.0194\n",
      "Epoch 7 Loss 0.0185\n",
      "Epoch 8 Loss 0.0171\n",
      "Epoch 9 Loss 0.0162\n",
      "Epoch 10 Loss 0.0173\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые украденные функции для оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "    \n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "#     plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! была ошибка с ticker - закоментил строку plot_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Input: <start> good morning <end>\n",
      "Predicted translation: ! <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['char', 'f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "translate(u'good morning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n",
    "    \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    \n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = len(inp_lang_tokenizer.index_word) + 2\n",
    "target_vocab_size = len(targ_lang_tokenizer.index_word) + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "  \n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "  \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.3544 Accuracy 0.2422\n",
      "Epoch 1 Batch 50 Loss 1.6176 Accuracy 0.2412\n",
      "Epoch 1 Batch 100 Loss 1.2922 Accuracy 0.2768\n",
      "Epoch 1 Loss 1.1361 Accuracy 0.3078\n",
      "Epoch 2 Batch 0 Loss 0.2639 Accuracy 0.4609\n",
      "Epoch 2 Batch 50 Loss 0.2261 Accuracy 0.4764\n",
      "Epoch 2 Batch 100 Loss 0.1894 Accuracy 0.4809\n",
      "Epoch 2 Loss 0.1755 Accuracy 0.4831\n",
      "Epoch 3 Batch 0 Loss 0.1612 Accuracy 0.4922\n",
      "Epoch 3 Batch 50 Loss 0.1178 Accuracy 0.4913\n",
      "Epoch 3 Batch 100 Loss 0.1201 Accuracy 0.4913\n",
      "Epoch 3 Loss 0.1176 Accuracy 0.4918\n",
      "Epoch 4 Batch 0 Loss 0.0939 Accuracy 0.4961\n",
      "Epoch 4 Batch 50 Loss 0.1139 Accuracy 0.4912\n",
      "Epoch 4 Batch 100 Loss 0.1057 Accuracy 0.4914\n",
      "Epoch 4 Loss 0.1058 Accuracy 0.4918\n",
      "Epoch 5 Batch 0 Loss 0.1004 Accuracy 0.4961\n",
      "Epoch 5 Batch 50 Loss 0.0818 Accuracy 0.4933\n",
      "Epoch 5 Batch 100 Loss 0.0875 Accuracy 0.4921\n",
      "Epoch 5 Loss 0.0880 Accuracy 0.4918\n",
      "Epoch 6 Batch 0 Loss 0.0782 Accuracy 0.4961\n",
      "Epoch 6 Batch 50 Loss 0.0845 Accuracy 0.4937\n",
      "Epoch 6 Batch 100 Loss 0.0811 Accuracy 0.4932\n",
      "Epoch 6 Loss 0.0797 Accuracy 0.4935\n",
      "Epoch 7 Batch 0 Loss 0.0355 Accuracy 0.5039\n",
      "Epoch 7 Batch 50 Loss 0.0635 Accuracy 0.4960\n",
      "Epoch 7 Batch 100 Loss 0.0674 Accuracy 0.4952\n",
      "Epoch 7 Loss 0.0695 Accuracy 0.4949\n",
      "Epoch 8 Batch 0 Loss 0.0583 Accuracy 0.4922\n",
      "Epoch 8 Batch 50 Loss 0.0625 Accuracy 0.4953\n",
      "Epoch 8 Batch 100 Loss 0.0653 Accuracy 0.4955\n",
      "Epoch 8 Loss 0.0645 Accuracy 0.4951\n",
      "Epoch 9 Batch 0 Loss 0.0907 Accuracy 0.4922\n",
      "Epoch 9 Batch 50 Loss 0.0576 Accuracy 0.4945\n",
      "Epoch 9 Batch 100 Loss 0.0663 Accuracy 0.4951\n",
      "Epoch 9 Loss 0.0661 Accuracy 0.4948\n",
      "Epoch 10 Batch 0 Loss 0.0441 Accuracy 0.4922\n",
      "Epoch 10 Batch 50 Loss 0.0642 Accuracy 0.4946\n",
      "Epoch 10 Batch 100 Loss 0.0565 Accuracy 0.4957\n",
      "Epoch 10 Loss 0.0570 Accuracy 0.4957\n",
      "Epoch 11 Batch 0 Loss 0.0674 Accuracy 0.4961\n",
      "Epoch 11 Batch 50 Loss 0.0489 Accuracy 0.4959\n",
      "Epoch 11 Batch 100 Loss 0.0550 Accuracy 0.4963\n",
      "Epoch 11 Loss 0.0578 Accuracy 0.4960\n",
      "Epoch 12 Batch 0 Loss 0.0291 Accuracy 0.5000\n",
      "Epoch 12 Batch 50 Loss 0.0571 Accuracy 0.4951\n",
      "Epoch 12 Batch 100 Loss 0.0554 Accuracy 0.4958\n",
      "Epoch 12 Loss 0.0543 Accuracy 0.4958\n",
      "Epoch 13 Batch 0 Loss 0.0532 Accuracy 0.5000\n",
      "Epoch 13 Batch 50 Loss 0.0524 Accuracy 0.4968\n",
      "Epoch 13 Batch 100 Loss 0.0527 Accuracy 0.4967\n",
      "Epoch 13 Loss 0.0515 Accuracy 0.4968\n",
      "Epoch 14 Batch 0 Loss 0.0092 Accuracy 0.5000\n",
      "Epoch 14 Batch 50 Loss 0.0519 Accuracy 0.4975\n",
      "Epoch 14 Batch 100 Loss 0.0545 Accuracy 0.4969\n",
      "Epoch 14 Loss 0.0524 Accuracy 0.4969\n",
      "Epoch 15 Batch 0 Loss 0.0499 Accuracy 0.5000\n",
      "Epoch 15 Batch 50 Loss 0.0681 Accuracy 0.4967\n",
      "Epoch 15 Batch 100 Loss 0.0646 Accuracy 0.4964\n",
      "Epoch 15 Loss 0.0615 Accuracy 0.4967\n",
      "Epoch 16 Batch 0 Loss 0.0211 Accuracy 0.5000\n",
      "Epoch 16 Batch 50 Loss 0.0455 Accuracy 0.4984\n",
      "Epoch 16 Batch 100 Loss 0.0454 Accuracy 0.4975\n",
      "Epoch 16 Loss 0.0473 Accuracy 0.4970\n",
      "Epoch 17 Batch 0 Loss 0.0281 Accuracy 0.5039\n",
      "Epoch 17 Batch 50 Loss 0.0368 Accuracy 0.4984\n",
      "Epoch 17 Batch 100 Loss 0.0462 Accuracy 0.4978\n",
      "Epoch 17 Loss 0.0498 Accuracy 0.4974\n",
      "Epoch 18 Batch 0 Loss 0.0384 Accuracy 0.5078\n",
      "Epoch 18 Batch 50 Loss 0.0479 Accuracy 0.4988\n",
      "Epoch 18 Batch 100 Loss 0.0527 Accuracy 0.4973\n",
      "Epoch 18 Loss 0.0513 Accuracy 0.4971\n",
      "Epoch 19 Batch 0 Loss 0.0163 Accuracy 0.5039\n",
      "Epoch 19 Batch 50 Loss 0.0444 Accuracy 0.4981\n",
      "Epoch 19 Batch 100 Loss 0.0429 Accuracy 0.4980\n",
      "Epoch 19 Loss 0.0452 Accuracy 0.4978\n",
      "Epoch 20 Batch 0 Loss 0.0455 Accuracy 0.4961\n",
      "Epoch 20 Batch 50 Loss 0.0423 Accuracy 0.4976\n",
      "Epoch 20 Batch 100 Loss 0.0451 Accuracy 0.4974\n",
      "Epoch 20 Loss 0.0442 Accuracy 0.4978\n",
      "Epoch 21 Batch 0 Loss 0.0388 Accuracy 0.4922\n",
      "Epoch 21 Batch 50 Loss 0.0440 Accuracy 0.4971\n",
      "Epoch 21 Batch 100 Loss 0.0486 Accuracy 0.4974\n",
      "Epoch 21 Loss 0.0480 Accuracy 0.4978\n",
      "Epoch 22 Batch 0 Loss 0.0334 Accuracy 0.4922\n",
      "Epoch 22 Batch 50 Loss 0.0437 Accuracy 0.4978\n",
      "Epoch 22 Batch 100 Loss 0.0457 Accuracy 0.4978\n",
      "Epoch 22 Loss 0.0457 Accuracy 0.4976\n",
      "Epoch 23 Batch 0 Loss 0.0614 Accuracy 0.5000\n",
      "Epoch 23 Batch 50 Loss 0.0474 Accuracy 0.4974\n",
      "Epoch 23 Batch 100 Loss 0.0434 Accuracy 0.4980\n",
      "Epoch 23 Loss 0.0431 Accuracy 0.4982\n",
      "Epoch 24 Batch 0 Loss 0.0238 Accuracy 0.5000\n",
      "Epoch 24 Batch 50 Loss 0.0507 Accuracy 0.4980\n",
      "Epoch 24 Batch 100 Loss 0.0480 Accuracy 0.4980\n",
      "Epoch 24 Loss 0.0485 Accuracy 0.4977\n",
      "Epoch 25 Batch 0 Loss 0.0728 Accuracy 0.4961\n",
      "Epoch 25 Batch 50 Loss 0.0413 Accuracy 0.4963\n",
      "Epoch 25 Batch 100 Loss 0.0472 Accuracy 0.4973\n",
      "Epoch 25 Loss 0.0474 Accuracy 0.4975\n",
      "Epoch 26 Batch 0 Loss 0.0607 Accuracy 0.4961\n",
      "Epoch 26 Batch 50 Loss 0.0439 Accuracy 0.4979\n",
      "Epoch 26 Batch 100 Loss 0.0442 Accuracy 0.4969\n",
      "Epoch 26 Loss 0.0461 Accuracy 0.4973\n",
      "Epoch 27 Batch 0 Loss 0.2645 Accuracy 0.4844\n",
      "Epoch 27 Batch 50 Loss 0.0557 Accuracy 0.4972\n",
      "Epoch 27 Batch 100 Loss 0.0510 Accuracy 0.4971\n",
      "Epoch 27 Loss 0.0524 Accuracy 0.4969\n",
      "Epoch 28 Batch 0 Loss 0.0733 Accuracy 0.5000\n",
      "Epoch 28 Batch 50 Loss 0.0449 Accuracy 0.4984\n",
      "Epoch 28 Batch 100 Loss 0.0488 Accuracy 0.4978\n",
      "Epoch 28 Loss 0.0510 Accuracy 0.4976\n",
      "Epoch 29 Batch 0 Loss 0.0133 Accuracy 0.5000\n",
      "Epoch 29 Batch 50 Loss 0.0505 Accuracy 0.4995\n",
      "Epoch 29 Batch 100 Loss 0.0508 Accuracy 0.4984\n",
      "Epoch 29 Loss 0.0500 Accuracy 0.4979\n",
      "Epoch 30 Batch 0 Loss 0.1059 Accuracy 0.4922\n",
      "Epoch 30 Batch 50 Loss 0.0436 Accuracy 0.4985\n",
      "Epoch 30 Batch 100 Loss 0.0567 Accuracy 0.4974\n",
      "Epoch 30 Loss 0.0558 Accuracy 0.4980\n",
      "Epoch 31 Batch 0 Loss 0.0224 Accuracy 0.5000\n",
      "Epoch 31 Batch 50 Loss 0.0655 Accuracy 0.4975\n",
      "Epoch 31 Batch 100 Loss 0.0612 Accuracy 0.4972\n",
      "Epoch 31 Loss 0.0602 Accuracy 0.4972\n",
      "Epoch 32 Batch 0 Loss 0.0364 Accuracy 0.4922\n",
      "Epoch 32 Batch 50 Loss 0.0451 Accuracy 0.4982\n",
      "Epoch 32 Batch 100 Loss 0.0511 Accuracy 0.4978\n",
      "Epoch 32 Loss 0.0522 Accuracy 0.4976\n",
      "Epoch 33 Batch 0 Loss 0.0109 Accuracy 0.5000\n",
      "Epoch 33 Batch 50 Loss 0.3053 Accuracy 0.4475\n",
      "Epoch 33 Batch 100 Loss 0.5965 Accuracy 0.3466\n",
      "Epoch 33 Loss 0.6448 Accuracy 0.3269\n",
      "Epoch 34 Batch 0 Loss 0.8649 Accuracy 0.2812\n",
      "Epoch 34 Batch 50 Loss 0.5011 Accuracy 0.3896\n",
      "Epoch 34 Batch 100 Loss 0.3472 Accuracy 0.4308\n",
      "Epoch 34 Loss 0.3171 Accuracy 0.4390\n",
      "Epoch 35 Batch 0 Loss 0.0935 Accuracy 0.4922\n",
      "Epoch 35 Batch 50 Loss 0.1495 Accuracy 0.4825\n",
      "Epoch 35 Batch 100 Loss 0.1348 Accuracy 0.4862\n",
      "Epoch 35 Loss 0.1309 Accuracy 0.4866\n",
      "Epoch 36 Batch 0 Loss 0.1390 Accuracy 0.4844\n",
      "Epoch 36 Batch 50 Loss 0.0996 Accuracy 0.4910\n",
      "Epoch 36 Batch 100 Loss 0.1540 Accuracy 0.4824\n",
      "Epoch 36 Loss 0.1475 Accuracy 0.4828\n",
      "Epoch 37 Batch 0 Loss 0.0377 Accuracy 0.4961\n",
      "Epoch 37 Batch 50 Loss 0.0987 Accuracy 0.4910\n",
      "Epoch 37 Batch 100 Loss 0.1015 Accuracy 0.4899\n",
      "Epoch 37 Loss 0.0991 Accuracy 0.4899\n",
      "Epoch 38 Batch 0 Loss 0.0685 Accuracy 0.4961\n",
      "Epoch 38 Batch 50 Loss 0.0872 Accuracy 0.4915\n",
      "Epoch 38 Batch 100 Loss 0.0937 Accuracy 0.4915\n",
      "Epoch 38 Loss 0.0989 Accuracy 0.4907\n",
      "Epoch 39 Batch 0 Loss 0.0785 Accuracy 0.4883\n",
      "Epoch 39 Batch 50 Loss 0.0919 Accuracy 0.4934\n",
      "Epoch 39 Batch 100 Loss 0.1381 Accuracy 0.4839\n",
      "Epoch 39 Loss 0.1302 Accuracy 0.4852\n",
      "Epoch 40 Batch 0 Loss 0.0971 Accuracy 0.4922\n",
      "Epoch 40 Batch 50 Loss 0.0897 Accuracy 0.4907\n",
      "Epoch 40 Batch 100 Loss 0.0862 Accuracy 0.4919\n",
      "Epoch 40 Loss 0.0880 Accuracy 0.4917\n",
      "Epoch 41 Batch 0 Loss 0.0679 Accuracy 0.4883\n",
      "Epoch 41 Batch 50 Loss 0.1123 Accuracy 0.4878\n",
      "Epoch 41 Batch 100 Loss 0.0952 Accuracy 0.4904\n",
      "Epoch 41 Loss 0.0939 Accuracy 0.4903\n",
      "Epoch 42 Batch 0 Loss 0.1160 Accuracy 0.4961\n",
      "Epoch 42 Batch 50 Loss 0.0899 Accuracy 0.4922\n",
      "Epoch 42 Batch 100 Loss 0.0784 Accuracy 0.4930\n",
      "Epoch 42 Loss 0.0830 Accuracy 0.4921\n",
      "Epoch 43 Batch 0 Loss 0.0338 Accuracy 0.5000\n",
      "Epoch 43 Batch 50 Loss 0.0855 Accuracy 0.4910\n",
      "Epoch 43 Batch 100 Loss 0.0849 Accuracy 0.4915\n",
      "Epoch 43 Loss 0.0869 Accuracy 0.4918\n",
      "Epoch 44 Batch 0 Loss 0.1457 Accuracy 0.4961\n",
      "Epoch 44 Batch 50 Loss 0.0954 Accuracy 0.4897\n",
      "Epoch 44 Batch 100 Loss 0.1000 Accuracy 0.4896\n",
      "Epoch 44 Loss 0.0924 Accuracy 0.4903\n",
      "Epoch 45 Batch 0 Loss 0.0480 Accuracy 0.5000\n",
      "Epoch 45 Batch 50 Loss 0.0825 Accuracy 0.4939\n",
      "Epoch 45 Batch 100 Loss 0.0754 Accuracy 0.4938\n",
      "Epoch 45 Loss 0.0744 Accuracy 0.4938\n",
      "Epoch 46 Batch 0 Loss 0.0340 Accuracy 0.5000\n",
      "Epoch 46 Batch 50 Loss 0.0744 Accuracy 0.4929\n",
      "Epoch 46 Batch 100 Loss 0.0893 Accuracy 0.4917\n",
      "Epoch 46 Loss 0.0841 Accuracy 0.4918\n",
      "Epoch 47 Batch 0 Loss 0.0302 Accuracy 0.4922\n",
      "Epoch 47 Batch 50 Loss 0.0811 Accuracy 0.4920\n",
      "Epoch 47 Batch 100 Loss 0.0780 Accuracy 0.4925\n",
      "Epoch 47 Loss 0.0793 Accuracy 0.4929\n",
      "Epoch 48 Batch 0 Loss 0.1626 Accuracy 0.4883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 50 Loss 0.0958 Accuracy 0.4902\n",
      "Epoch 48 Batch 100 Loss 0.0976 Accuracy 0.4893\n",
      "Epoch 48 Loss 0.0939 Accuracy 0.4897\n",
      "Epoch 49 Batch 0 Loss 0.0518 Accuracy 0.4961\n",
      "Epoch 49 Batch 50 Loss 0.0721 Accuracy 0.4939\n",
      "Epoch 49 Batch 100 Loss 0.0743 Accuracy 0.4933\n",
      "Epoch 49 Loss 0.0752 Accuracy 0.4930\n",
      "Epoch 50 Batch 0 Loss 0.0287 Accuracy 0.4922\n",
      "Epoch 50 Batch 50 Loss 0.0563 Accuracy 0.4953\n",
      "Epoch 50 Batch 100 Loss 0.0714 Accuracy 0.4944\n",
      "Epoch 50 Loss 0.0700 Accuracy 0.4944\n",
      "Epoch 51 Batch 0 Loss 0.0238 Accuracy 0.5000\n",
      "Epoch 51 Batch 50 Loss 0.0795 Accuracy 0.4936\n",
      "Epoch 51 Batch 100 Loss 0.0892 Accuracy 0.4923\n",
      "Epoch 51 Loss 0.0911 Accuracy 0.4922\n",
      "Epoch 52 Batch 0 Loss 0.0327 Accuracy 0.5000\n",
      "Epoch 52 Batch 50 Loss 0.1088 Accuracy 0.4890\n",
      "Epoch 52 Batch 100 Loss 0.0952 Accuracy 0.4914\n",
      "Epoch 52 Loss 0.0905 Accuracy 0.4919\n",
      "Epoch 53 Batch 0 Loss 0.1374 Accuracy 0.4961\n",
      "Epoch 53 Batch 50 Loss 0.0723 Accuracy 0.4949\n",
      "Epoch 53 Batch 100 Loss 0.0902 Accuracy 0.4918\n",
      "Epoch 53 Loss 0.0853 Accuracy 0.4923\n",
      "Epoch 54 Batch 0 Loss 0.0201 Accuracy 0.5000\n",
      "Epoch 54 Batch 50 Loss 0.0724 Accuracy 0.4939\n",
      "Epoch 54 Batch 100 Loss 0.0702 Accuracy 0.4941\n",
      "Epoch 54 Loss 0.0714 Accuracy 0.4938\n",
      "Epoch 55 Batch 0 Loss 0.0573 Accuracy 0.4883\n",
      "Epoch 55 Batch 50 Loss 0.0714 Accuracy 0.4943\n",
      "Epoch 55 Batch 100 Loss 0.0772 Accuracy 0.4928\n",
      "Epoch 55 Loss 0.0724 Accuracy 0.4931\n",
      "Epoch 56 Batch 0 Loss 0.0344 Accuracy 0.5039\n",
      "Epoch 56 Batch 50 Loss 0.0678 Accuracy 0.4945\n",
      "Epoch 56 Batch 100 Loss 0.0635 Accuracy 0.4950\n",
      "Epoch 56 Loss 0.0747 Accuracy 0.4937\n",
      "Epoch 57 Batch 0 Loss 0.0744 Accuracy 0.4961\n",
      "Epoch 57 Batch 50 Loss 0.0647 Accuracy 0.4951\n",
      "Epoch 57 Batch 100 Loss 0.0689 Accuracy 0.4945\n",
      "Epoch 57 Loss 0.0683 Accuracy 0.4947\n",
      "Epoch 58 Batch 0 Loss 0.0977 Accuracy 0.4922\n",
      "Epoch 58 Batch 50 Loss 0.0681 Accuracy 0.4934\n",
      "Epoch 58 Batch 100 Loss 0.0823 Accuracy 0.4918\n",
      "Epoch 58 Loss 0.0779 Accuracy 0.4923\n",
      "Epoch 59 Batch 0 Loss 0.0566 Accuracy 0.4961\n",
      "Epoch 59 Batch 50 Loss 0.0581 Accuracy 0.4956\n",
      "Epoch 59 Batch 100 Loss 0.0642 Accuracy 0.4947\n",
      "Epoch 59 Loss 0.0664 Accuracy 0.4947\n",
      "Epoch 60 Batch 0 Loss 0.0464 Accuracy 0.4883\n",
      "Epoch 60 Batch 50 Loss 0.1052 Accuracy 0.4899\n",
      "Epoch 60 Batch 100 Loss 0.0828 Accuracy 0.4924\n",
      "Epoch 60 Loss 0.0838 Accuracy 0.4922\n",
      "Epoch 61 Batch 0 Loss 0.0630 Accuracy 0.4922\n",
      "Epoch 61 Batch 50 Loss 0.0601 Accuracy 0.4950\n",
      "Epoch 61 Batch 100 Loss 0.0643 Accuracy 0.4946\n",
      "Epoch 61 Loss 0.0774 Accuracy 0.4937\n",
      "Epoch 62 Batch 0 Loss 0.1128 Accuracy 0.4922\n",
      "Epoch 62 Batch 50 Loss 0.0642 Accuracy 0.4936\n",
      "Epoch 62 Batch 100 Loss 0.0612 Accuracy 0.4945\n",
      "Epoch 62 Loss 0.0638 Accuracy 0.4943\n",
      "Epoch 63 Batch 0 Loss 0.0111 Accuracy 0.5000\n",
      "Epoch 63 Batch 50 Loss 0.0680 Accuracy 0.4953\n",
      "Epoch 63 Batch 100 Loss 0.0684 Accuracy 0.4942\n",
      "Epoch 63 Loss 0.0703 Accuracy 0.4940\n",
      "Epoch 64 Batch 0 Loss 0.0755 Accuracy 0.4922\n",
      "Epoch 64 Batch 50 Loss 0.0712 Accuracy 0.4949\n",
      "Epoch 64 Batch 100 Loss 0.0736 Accuracy 0.4945\n",
      "Epoch 64 Loss 0.0692 Accuracy 0.4948\n",
      "Epoch 65 Batch 0 Loss 0.1799 Accuracy 0.4844\n",
      "Epoch 65 Batch 50 Loss 0.0685 Accuracy 0.4935\n",
      "Epoch 65 Batch 100 Loss 0.0732 Accuracy 0.4933\n",
      "Epoch 65 Loss 0.0728 Accuracy 0.4936\n",
      "Epoch 66 Batch 0 Loss 0.0759 Accuracy 0.4922\n",
      "Epoch 66 Batch 50 Loss 0.0730 Accuracy 0.4941\n",
      "Epoch 66 Batch 100 Loss 0.0740 Accuracy 0.4934\n",
      "Epoch 66 Loss 0.0731 Accuracy 0.4935\n",
      "Epoch 67 Batch 0 Loss 0.0478 Accuracy 0.4961\n",
      "Epoch 67 Batch 50 Loss 0.0664 Accuracy 0.4943\n",
      "Epoch 67 Batch 100 Loss 0.0665 Accuracy 0.4945\n",
      "Epoch 67 Loss 0.0659 Accuracy 0.4946\n",
      "Epoch 68 Batch 0 Loss 0.0259 Accuracy 0.4961\n",
      "Epoch 68 Batch 50 Loss 0.0744 Accuracy 0.4939\n",
      "Epoch 68 Batch 100 Loss 0.0708 Accuracy 0.4943\n",
      "Epoch 68 Loss 0.0740 Accuracy 0.4939\n",
      "Epoch 69 Batch 0 Loss 0.2018 Accuracy 0.4883\n",
      "Epoch 69 Batch 50 Loss 0.0618 Accuracy 0.4950\n",
      "Epoch 69 Batch 100 Loss 0.0681 Accuracy 0.4949\n",
      "Epoch 69 Loss 0.0688 Accuracy 0.4945\n",
      "Epoch 70 Batch 0 Loss 0.0300 Accuracy 0.5000\n",
      "Epoch 70 Batch 50 Loss 0.0696 Accuracy 0.4959\n",
      "Epoch 70 Batch 100 Loss 0.0740 Accuracy 0.4946\n",
      "Epoch 70 Loss 0.0727 Accuracy 0.4944\n",
      "Epoch 71 Batch 0 Loss 0.1506 Accuracy 0.4883\n",
      "Epoch 71 Batch 50 Loss 0.0628 Accuracy 0.4947\n",
      "Epoch 71 Batch 100 Loss 0.0685 Accuracy 0.4941\n",
      "Epoch 71 Loss 0.0680 Accuracy 0.4942\n",
      "Epoch 72 Batch 0 Loss 0.0200 Accuracy 0.4961\n",
      "Epoch 72 Batch 50 Loss 0.0638 Accuracy 0.4943\n",
      "Epoch 72 Batch 100 Loss 0.0708 Accuracy 0.4940\n",
      "Epoch 72 Loss 0.0691 Accuracy 0.4943\n",
      "Epoch 73 Batch 0 Loss 0.0174 Accuracy 0.5000\n",
      "Epoch 73 Batch 50 Loss 0.0704 Accuracy 0.4943\n",
      "Epoch 73 Batch 100 Loss 0.0686 Accuracy 0.4947\n",
      "Epoch 73 Loss 0.0688 Accuracy 0.4945\n",
      "Epoch 74 Batch 0 Loss 0.0813 Accuracy 0.4961\n",
      "Epoch 74 Batch 50 Loss 0.0755 Accuracy 0.4946\n",
      "Epoch 74 Batch 100 Loss 0.0797 Accuracy 0.4942\n",
      "Epoch 74 Loss 0.0815 Accuracy 0.4943\n",
      "Epoch 75 Batch 0 Loss 0.0524 Accuracy 0.5000\n",
      "Epoch 75 Batch 50 Loss 0.0599 Accuracy 0.4956\n",
      "Epoch 75 Batch 100 Loss 0.0743 Accuracy 0.4945\n",
      "Epoch 75 Loss 0.0733 Accuracy 0.4945\n",
      "Epoch 76 Batch 0 Loss 0.1236 Accuracy 0.4922\n",
      "Epoch 76 Batch 50 Loss 0.0735 Accuracy 0.4949\n",
      "Epoch 76 Batch 100 Loss 0.0732 Accuracy 0.4939\n",
      "Epoch 76 Loss 0.0707 Accuracy 0.4942\n",
      "Epoch 77 Batch 0 Loss 0.0212 Accuracy 0.4961\n",
      "Epoch 77 Batch 50 Loss 0.0796 Accuracy 0.4929\n",
      "Epoch 77 Batch 100 Loss 0.0765 Accuracy 0.4939\n",
      "Epoch 77 Loss 0.0755 Accuracy 0.4937\n",
      "Epoch 78 Batch 0 Loss 0.0738 Accuracy 0.4883\n",
      "Epoch 78 Batch 50 Loss 0.0841 Accuracy 0.4925\n",
      "Epoch 78 Batch 100 Loss 0.0747 Accuracy 0.4934\n",
      "Epoch 78 Loss 0.0715 Accuracy 0.4941\n",
      "Epoch 79 Batch 0 Loss 0.0432 Accuracy 0.4922\n",
      "Epoch 79 Batch 50 Loss 0.0621 Accuracy 0.4949\n",
      "Epoch 79 Batch 100 Loss 0.0672 Accuracy 0.4947\n",
      "Epoch 79 Loss 0.0675 Accuracy 0.4945\n",
      "Epoch 80 Batch 0 Loss 0.2706 Accuracy 0.4844\n",
      "Epoch 80 Batch 50 Loss 0.0685 Accuracy 0.4944\n",
      "Epoch 80 Batch 100 Loss 0.0726 Accuracy 0.4939\n",
      "Epoch 80 Loss 0.0748 Accuracy 0.4933\n",
      "Epoch 81 Batch 0 Loss 0.1149 Accuracy 0.4844\n",
      "Epoch 81 Batch 50 Loss 0.0657 Accuracy 0.4953\n",
      "Epoch 81 Batch 100 Loss 0.0652 Accuracy 0.4952\n",
      "Epoch 81 Loss 0.0673 Accuracy 0.4949\n",
      "Epoch 82 Batch 0 Loss 0.0727 Accuracy 0.4883\n",
      "Epoch 82 Batch 50 Loss 0.0656 Accuracy 0.4946\n",
      "Epoch 82 Batch 100 Loss 0.0679 Accuracy 0.4949\n",
      "Epoch 82 Loss 0.0664 Accuracy 0.4949\n",
      "Epoch 83 Batch 0 Loss 0.0748 Accuracy 0.4961\n",
      "Epoch 83 Batch 50 Loss 0.0566 Accuracy 0.4953\n",
      "Epoch 83 Batch 100 Loss 0.0627 Accuracy 0.4943\n",
      "Epoch 83 Loss 0.0636 Accuracy 0.4947\n",
      "Epoch 84 Batch 0 Loss 0.0161 Accuracy 0.5039\n",
      "Epoch 84 Batch 50 Loss 0.0628 Accuracy 0.4956\n",
      "Epoch 84 Batch 100 Loss 0.0670 Accuracy 0.4947\n",
      "Epoch 84 Loss 0.0660 Accuracy 0.4949\n",
      "Epoch 85 Batch 0 Loss 0.0371 Accuracy 0.4961\n",
      "Epoch 85 Batch 50 Loss 0.0749 Accuracy 0.4944\n",
      "Epoch 85 Batch 100 Loss 0.0748 Accuracy 0.4937\n",
      "Epoch 85 Loss 0.0734 Accuracy 0.4941\n",
      "Epoch 86 Batch 0 Loss 0.0346 Accuracy 0.4961\n",
      "Epoch 86 Batch 50 Loss 0.0575 Accuracy 0.4953\n",
      "Epoch 86 Batch 100 Loss 0.0670 Accuracy 0.4949\n",
      "Epoch 86 Loss 0.0677 Accuracy 0.4945\n",
      "Epoch 87 Batch 0 Loss 0.0661 Accuracy 0.5000\n",
      "Epoch 87 Batch 50 Loss 0.0676 Accuracy 0.4942\n",
      "Epoch 87 Batch 100 Loss 0.0625 Accuracy 0.4940\n",
      "Epoch 87 Loss 0.0653 Accuracy 0.4940\n",
      "Epoch 88 Batch 0 Loss 0.0878 Accuracy 0.4883\n",
      "Epoch 88 Batch 50 Loss 0.0668 Accuracy 0.4936\n",
      "Epoch 88 Batch 100 Loss 0.0718 Accuracy 0.4935\n",
      "Epoch 88 Loss 0.0691 Accuracy 0.4937\n",
      "Epoch 89 Batch 0 Loss 0.0206 Accuracy 0.4961\n",
      "Epoch 89 Batch 50 Loss 0.0708 Accuracy 0.4939\n",
      "Epoch 89 Batch 100 Loss 0.0697 Accuracy 0.4939\n",
      "Epoch 89 Loss 0.0686 Accuracy 0.4940\n",
      "Epoch 90 Batch 0 Loss 0.0731 Accuracy 0.4922\n",
      "Epoch 90 Batch 50 Loss 0.0557 Accuracy 0.4956\n",
      "Epoch 90 Batch 100 Loss 0.0624 Accuracy 0.4948\n",
      "Epoch 90 Loss 0.0686 Accuracy 0.4939\n",
      "Epoch 91 Batch 0 Loss 0.0313 Accuracy 0.4922\n",
      "Epoch 91 Batch 50 Loss 0.0510 Accuracy 0.4951\n",
      "Epoch 91 Batch 100 Loss 0.0561 Accuracy 0.4951\n",
      "Epoch 91 Loss 0.0589 Accuracy 0.4951\n",
      "Epoch 92 Batch 0 Loss 0.0367 Accuracy 0.5039\n",
      "Epoch 92 Batch 50 Loss 0.0668 Accuracy 0.4943\n",
      "Epoch 92 Batch 100 Loss 0.0629 Accuracy 0.4942\n",
      "Epoch 92 Loss 0.0621 Accuracy 0.4942\n",
      "Epoch 93 Batch 0 Loss 0.0488 Accuracy 0.5000\n",
      "Epoch 93 Batch 50 Loss 0.0707 Accuracy 0.4943\n",
      "Epoch 93 Batch 100 Loss 0.0660 Accuracy 0.4947\n",
      "Epoch 93 Loss 0.0638 Accuracy 0.4945\n",
      "Epoch 94 Batch 0 Loss 0.0702 Accuracy 0.4883\n",
      "Epoch 94 Batch 50 Loss 0.0574 Accuracy 0.4949\n",
      "Epoch 94 Batch 100 Loss 0.0647 Accuracy 0.4939\n",
      "Epoch 94 Loss 0.0642 Accuracy 0.4940\n",
      "Epoch 95 Batch 0 Loss 0.0695 Accuracy 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 50 Loss 0.0534 Accuracy 0.4952\n",
      "Epoch 95 Batch 100 Loss 0.0548 Accuracy 0.4952\n",
      "Epoch 95 Loss 0.0555 Accuracy 0.4952\n",
      "Epoch 96 Batch 0 Loss 0.0300 Accuracy 0.5039\n",
      "Epoch 96 Batch 50 Loss 0.0420 Accuracy 0.4967\n",
      "Epoch 96 Batch 100 Loss 0.0527 Accuracy 0.4956\n",
      "Epoch 96 Loss 0.0543 Accuracy 0.4952\n",
      "Epoch 97 Batch 0 Loss 0.1096 Accuracy 0.4922\n",
      "Epoch 97 Batch 50 Loss 0.0617 Accuracy 0.4953\n",
      "Epoch 97 Batch 100 Loss 0.0555 Accuracy 0.4952\n",
      "Epoch 97 Loss 0.0567 Accuracy 0.4955\n",
      "Epoch 98 Batch 0 Loss 0.0424 Accuracy 0.5000\n",
      "Epoch 98 Batch 50 Loss 0.0463 Accuracy 0.4967\n",
      "Epoch 98 Batch 100 Loss 0.0547 Accuracy 0.4958\n",
      "Epoch 98 Loss 0.0531 Accuracy 0.4957\n",
      "Epoch 99 Batch 0 Loss 0.0384 Accuracy 0.4922\n",
      "Epoch 99 Batch 50 Loss 0.0615 Accuracy 0.4946\n",
      "Epoch 99 Batch 100 Loss 0.0552 Accuracy 0.4950\n",
      "Epoch 99 Loss 0.0568 Accuracy 0.4951\n",
      "Epoch 100 Batch 0 Loss 0.0369 Accuracy 0.4961\n",
      "Epoch 100 Batch 50 Loss 0.0545 Accuracy 0.4960\n",
      "Epoch 100 Batch 100 Loss 0.0533 Accuracy 0.4959\n",
      "Epoch 100 Loss 0.0538 Accuracy 0.4959\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        train_step(inp, tar)\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: good morning.\n",
      "Predicted translation: ['<start>', '.', '.', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [1]\n",
    "    end_token = [2]\n",
    "  \n",
    "    sentence = preprocess_sentence(inp_sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    \n",
    "    encoder_input = tf.expand_dims(inputs, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "    decoder_input = [1]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(max_length_targ):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == targ_lang_tokenizer.word_index[\"<end>\"]:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "\n",
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "    sentence = inp_lang_tokenizer.encode(sentence)\n",
    "  \n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "    predicted_sentence = ([targ_lang_tokenizer.index_word[i] for i in result.numpy()])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)\n",
    "        \n",
    "translate(\"good morning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: hi\n",
      "Predicted translation: ['<start>', '.', '.', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "translate(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 часа трейна и вот такое на выходе XD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
