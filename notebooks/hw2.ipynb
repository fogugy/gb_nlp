{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.8/site-packages (from nltk) (2020.7.14)\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.8/site-packages (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.8/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.8/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.8/site-packages (from gensim) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim) (1.14.28)\n",
      "Requirement already satisfied: boto in /opt/conda/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.28 in /opt/conda/lib/python3.8/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.28)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore<1.18.0,>=1.17.28->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.8/site-packages (from botocore<1.18.0,>=1.17.28->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import gensim\n",
    "import pickle\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import os\n",
    "import re\n",
    "from html.parser import HTMLParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./prepared.pickle', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49159 entries, 0 to 49158\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    49159 non-null  int64  \n",
      " 1   label                 31962 non-null  float64\n",
      " 2   tweet                 49159 non-null  object \n",
      " 3   clean_tweet           49159 non-null  object \n",
      " 4   tweet_token           49159 non-null  object \n",
      " 5   tweet_token_filtered  49159 non-null  object \n",
      " 6   tweet_stemmed         49159 non-null  object \n",
      " 7   tweet_lemmatized      49159 non-null  object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love you take with you all the time in urð</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, urð]</td>\n",
       "      <td>[model, love, take, time, urð]</td>\n",
       "      <td>[model, love, take, time, urð]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when father is dysfunctional and is so selfish...   \n",
       "1  thanks for lyft credit cannot use cause they d...   \n",
       "2                                bihday your majesty   \n",
       "3   model love you take with you all the time in urð   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                     [model, love, take, time, urð]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                     [model, love, take, time, urð]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...  \n",
       "2                                  [bihday, majesty]  \n",
       "3                     [model, love, take, time, urð]  \n",
       "4                  [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform().  \n",
    "Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "\n",
    "\n",
    "- Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "- Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "- Исключим стоп-слова с помощью stop_words='english'.\n",
    "- Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bow_vectorizer = sklearn.feature_extraction.text.CountVectorizer(max_df=0.90, max_features=1000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_st_all = np.array([item for sublist in df['tweet_stemmed'] for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_stemmed = count_bow_vectorizer.fit_transform(tw_st_all)\n",
    "count_bow_stemmed = pd.DataFrame.sparse.from_spmatrix(columns=count_bow_vectorizer.get_feature_names(), data=bow_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_lem_all = np.array([item for sublist in df['tweet_lemmatized'] for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_lemma = count_bow_vectorizer.fit_transform(tw_lem_all)\n",
    "count_bow_lemma = pd.DataFrame.sparse.from_spmatrix(columns=count_bow_vectorizer.get_feature_names(), data=bow_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.  \n",
    "\n",
    "\n",
    "- Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "- Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "- Исключим стоп-слова с помощью stop_words='english'.\n",
    "- Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_bow_vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.90, max_features=1000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_stemmed = tfidf_bow_vectorizer.fit_transform(tw_st_all)\n",
    "tfidf_bow_stemmed = pd.DataFrame.sparse.from_spmatrix(columns=tfidf_bow_vectorizer.get_feature_names(), data=bow_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_lemma = count_bow_vectorizer.fit_transform(tw_lem_all)\n",
    "tfidf_bow_lemma = pd.DataFrame.sparse.from_spmatrix(columns=tfidf_bow_vectorizer.get_feature_names(), data=bow_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Натренируем gensim.models.Word2Vec модель на наших данных.  \n",
    "Тренировать будем на токенизированных твитах combine_df['tweet_token']  \n",
    "\n",
    "\n",
    "- Установим следующие параметры: size=200, window=5, min_count=2, sg = 1, hs = 0, negative = 10, workers= 32, seed = 34.\n",
    "- Используем функцию train() с параметром total_examples равным длине combine_df['tweet_token'], количество epochs установим 20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vectorizer = Word2Vec(corpus_file='./corpus', size=200, window=5, min_count=1, sg=1, hs=0, negative=10, workers=32, seed=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7958411, 11782200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectorizer.train(df['tweet_token'], total_examples=df['tweet_token'].shape[0], epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vectorizer.save('w2v_vectorizer.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Давайте немного потестируем нашу модель Word2Vec и посмотрим, как она работает. Мы зададим слово positive = \"dinner\", и модель вытащит из корпуса наиболее похожие слова c помощью функции most_similar. То же самое попробуем со словом \"trump\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pasta', 0.6841076016426086),\n",
       " ('pancakes', 0.6751857995986938),\n",
       " ('salsa', 0.6703296899795532),\n",
       " ('candlelight', 0.6688082218170166),\n",
       " ('lunch', 0.6660800576210022),\n",
       " ('showers', 0.6659550666809082),\n",
       " ('spiral', 0.6636358499526978),\n",
       " ('cork', 0.6632431149482727),\n",
       " ('favs', 0.6604034900665283),\n",
       " ('smoothie', 0.6599393486976624)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectorizer.most_similar(positive=\"dinner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('slammed', 0.6073219776153564),\n",
       " ('Leonard', 0.5960643291473389),\n",
       " ('fail.', 0.5952973365783691),\n",
       " ('inviting', 0.5939775705337524),\n",
       " ('Garnell', 0.5925332903862),\n",
       " ('\"get\"', 0.5920398831367493),\n",
       " ('Pinth', 0.5918149352073669),\n",
       " ('interventions', 0.5918017625808716),\n",
       " ('Woody', 0.5916659832000732),\n",
       " ('Firemen', 0.590410053730011)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectorizer.most_similar(\"trump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Из приведенных выше примеров мы видим, что наша модель word2vec хорошо справляется с поиском наиболее похожих слов для данного слова. Но как она это делает? Она изучила векторы для каждого уникального слова наших данных и использует косинусное сходство, чтобы найти наиболее похожие векторы (слова).\n",
    "Давайте проверим векторное представление любого слова из нашего корпуса, например \"food\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = 'food'\n",
    "model = w2v_vectorizer\n",
    "\n",
    "arr = np.empty((0,200), dtype='f')\n",
    "word_labels = [word]\n",
    "\n",
    "close_words = model.similar_by_word(word)\n",
    "not_close_words = ['dog', 'banana', 'car', 'computer']\n",
    "\n",
    "arr = np.append(arr, np.array([model[word]]), axis=0)\n",
    "for wrd_score in close_words:\n",
    "    wrd_vector = model[wrd_score[0]]\n",
    "    word_labels.append(wrd_score[0])\n",
    "    arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "    \n",
    "for wrd in not_close_words:\n",
    "    wrd_vector = model[wrd]\n",
    "    word_labels.append(wrd)\n",
    "    arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "np.set_printoptions(suppress=True)\n",
    "Y = tsne.fit_transform(arr)\n",
    "\n",
    "x_coords = Y[:, 0]\n",
    "y_coords = Y[:, 1]\n",
    "# display scatter plot\n",
    "plt.scatter(x_coords, y_coords)\n",
    "\n",
    "for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "    plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "# plt.xlim(x_coords.min()+0.5, x_coords.max()+0.5)\n",
    "# plt.ylim(y_coords.min()+0.5, y_coords.max()+0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.. почему так плохо?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Поскольку наши данные содержат твиты, а не только слова, нам придется придумать способ использовать векторы слов из модели word2vec для создания векторного представления всего твита. Существует простое решение этой проблемы, мы можем просто взять среднее значение всех векторов слов, присутствующих в твите. Длина результирующего вектора будет одинаковой, то есть 200. Мы повторим тот же процесс для всех твитов в наших данных и получим их векторы. Теперь у нас есть 200 функций word2vec для наших данных.\n",
    "Необходимо создать вектор для каждого твита, взяв среднее значение векторов слов, присутствующих в твите. В цикле сделать:  vec += model_w2v[word].reshape((1, size))\n",
    "и поделить финальный вектор на количество слов в твите.\n",
    "На выходе должен получиться wordvec_df.shape = (49159, 200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in range(df['tweet_token_filtered'].shape[0]):\n",
    "    vec = []\n",
    "\n",
    "    for word in df['tweet_token_filtered'][0]:\n",
    "        try:\n",
    "            vec.append(model[word])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    np_vec = np.array(vec)\n",
    "    data.append(list(np_vec.sum(axis=0)/np_vec.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49159, 200)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[x for x in range(200)]\n",
    "wordvec_df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710511</td>\n",
       "      <td>-0.068873</td>\n",
       "      <td>0.30613</td>\n",
       "      <td>0.102179</td>\n",
       "      <td>0.171617</td>\n",
       "      <td>0.313152</td>\n",
       "      <td>0.170175</td>\n",
       "      <td>-0.194134</td>\n",
       "      <td>0.152823</td>\n",
       "      <td>-0.020243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11687</td>\n",
       "      <td>0.194347</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>-0.077486</td>\n",
       "      <td>0.528871</td>\n",
       "      <td>0.290712</td>\n",
       "      <td>-0.280655</td>\n",
       "      <td>-0.0071</td>\n",
       "      <td>-0.370079</td>\n",
       "      <td>-0.332591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.710511</td>\n",
       "      <td>-0.068873</td>\n",
       "      <td>0.30613</td>\n",
       "      <td>0.102179</td>\n",
       "      <td>0.171617</td>\n",
       "      <td>0.313152</td>\n",
       "      <td>0.170175</td>\n",
       "      <td>-0.194134</td>\n",
       "      <td>0.152823</td>\n",
       "      <td>-0.020243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11687</td>\n",
       "      <td>0.194347</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>-0.077486</td>\n",
       "      <td>0.528871</td>\n",
       "      <td>0.290712</td>\n",
       "      <td>-0.280655</td>\n",
       "      <td>-0.0071</td>\n",
       "      <td>-0.370079</td>\n",
       "      <td>-0.332591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.710511</td>\n",
       "      <td>-0.068873</td>\n",
       "      <td>0.30613</td>\n",
       "      <td>0.102179</td>\n",
       "      <td>0.171617</td>\n",
       "      <td>0.313152</td>\n",
       "      <td>0.170175</td>\n",
       "      <td>-0.194134</td>\n",
       "      <td>0.152823</td>\n",
       "      <td>-0.020243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11687</td>\n",
       "      <td>0.194347</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>-0.077486</td>\n",
       "      <td>0.528871</td>\n",
       "      <td>0.290712</td>\n",
       "      <td>-0.280655</td>\n",
       "      <td>-0.0071</td>\n",
       "      <td>-0.370079</td>\n",
       "      <td>-0.332591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.710511</td>\n",
       "      <td>-0.068873</td>\n",
       "      <td>0.30613</td>\n",
       "      <td>0.102179</td>\n",
       "      <td>0.171617</td>\n",
       "      <td>0.313152</td>\n",
       "      <td>0.170175</td>\n",
       "      <td>-0.194134</td>\n",
       "      <td>0.152823</td>\n",
       "      <td>-0.020243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11687</td>\n",
       "      <td>0.194347</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>-0.077486</td>\n",
       "      <td>0.528871</td>\n",
       "      <td>0.290712</td>\n",
       "      <td>-0.280655</td>\n",
       "      <td>-0.0071</td>\n",
       "      <td>-0.370079</td>\n",
       "      <td>-0.332591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.710511</td>\n",
       "      <td>-0.068873</td>\n",
       "      <td>0.30613</td>\n",
       "      <td>0.102179</td>\n",
       "      <td>0.171617</td>\n",
       "      <td>0.313152</td>\n",
       "      <td>0.170175</td>\n",
       "      <td>-0.194134</td>\n",
       "      <td>0.152823</td>\n",
       "      <td>-0.020243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11687</td>\n",
       "      <td>0.194347</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>-0.077486</td>\n",
       "      <td>0.528871</td>\n",
       "      <td>0.290712</td>\n",
       "      <td>-0.280655</td>\n",
       "      <td>-0.0071</td>\n",
       "      <td>-0.370079</td>\n",
       "      <td>-0.332591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1        2         3         4         5         6    \\\n",
       "0  0.710511 -0.068873  0.30613  0.102179  0.171617  0.313152  0.170175   \n",
       "1  0.710511 -0.068873  0.30613  0.102179  0.171617  0.313152  0.170175   \n",
       "2  0.710511 -0.068873  0.30613  0.102179  0.171617  0.313152  0.170175   \n",
       "3  0.710511 -0.068873  0.30613  0.102179  0.171617  0.313152  0.170175   \n",
       "4  0.710511 -0.068873  0.30613  0.102179  0.171617  0.313152  0.170175   \n",
       "\n",
       "        7         8         9    ...      190       191       192       193  \\\n",
       "0 -0.194134  0.152823 -0.020243  ... -0.11687  0.194347  0.039535 -0.077486   \n",
       "1 -0.194134  0.152823 -0.020243  ... -0.11687  0.194347  0.039535 -0.077486   \n",
       "2 -0.194134  0.152823 -0.020243  ... -0.11687  0.194347  0.039535 -0.077486   \n",
       "3 -0.194134  0.152823 -0.020243  ... -0.11687  0.194347  0.039535 -0.077486   \n",
       "4 -0.194134  0.152823 -0.020243  ... -0.11687  0.194347  0.039535 -0.077486   \n",
       "\n",
       "        194       195       196     197       198       199  \n",
       "0  0.528871  0.290712 -0.280655 -0.0071 -0.370079 -0.332591  \n",
       "1  0.528871  0.290712 -0.280655 -0.0071 -0.370079 -0.332591  \n",
       "2  0.528871  0.290712 -0.280655 -0.0071 -0.370079 -0.332591  \n",
       "3  0.528871  0.290712 -0.280655 -0.0071 -0.370079 -0.332591  \n",
       "4  0.528871  0.290712 -0.280655 -0.0071 -0.370079 -0.332591  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
